#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å†…å­˜åˆ°GPUè¿ç§»å®æ–½æ–¹æ¡ˆ
é’ˆå¯¹AI-Aimboté¡¹ç›®çš„å…·ä½“ä¼˜åŒ–å»ºè®®
"""

import torch
import numpy as np
import cv2
import mss
from ultralytics import YOLO
import time

class GPUOptimizedAimbot:
    """GPUä¼˜åŒ–çš„ç„å‡†æœºå™¨äºº"""
    
    def __init__(self):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ä½¿ç”¨è®¾å¤‡: {self.device}")
        
        # é¢„åˆ†é…GPUå†…å­˜
        self.setup_gpu_memory()
        
        # åŠ è½½æ¨¡å‹åˆ°GPU
        self.load_model()
    
    def setup_gpu_memory(self):
        """é¢„åˆ†é…GPUå†…å­˜ï¼Œé¿å…è¿è¡Œæ—¶åˆ†é…å»¶è¿Ÿ"""
        if self.device.type == 'cuda':
            # é¢„åˆ†é…å¸¸ç”¨å¼ é‡
            self.gpu_image_buffer = torch.zeros((3, 416, 416), dtype=torch.float32, device=self.device)
            self.gpu_resized_buffer = torch.zeros((3, 320, 320), dtype=torch.float32, device=self.device)
            print("âœ… GPUå†…å­˜é¢„åˆ†é…å®Œæˆ")
    
    def load_model(self):
        """åŠ è½½æ¨¡å‹åˆ°GPUå¹¶é¢„çƒ­"""
        try:
            self.model = YOLO('models/valorant/best.pt')
            self.model.to(self.device)
            
            # æ¨¡å‹é¢„çƒ­
            print("ğŸ”¥ GPUæ¨¡å‹é¢„çƒ­ä¸­...")
            dummy_input = torch.randn(1, 3, 416, 416, device=self.device)
            with torch.no_grad():
                for _ in range(3):
                    # ä½¿ç”¨numpyæ•°ç»„è¿›è¡Œé¢„çƒ­ï¼ˆåŒ¹é…å®é™…ä½¿ç”¨ï¼‰
                    dummy_np = dummy_input.cpu().numpy().transpose(0, 2, 3, 1)[0]
                    _ = self.model.predict(dummy_np, device=self.device, verbose=False)
            
            print("âœ… æ¨¡å‹é¢„çƒ­å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            self.model = None
    
    def gpu_image_preprocessing(self, screenshot_np):
        """GPUåŠ é€Ÿçš„å›¾åƒé¢„å¤„ç†"""
        if self.device.type == 'cpu':
            # CPUå›é€€æ–¹æ¡ˆ
            return torch.nn.functional.interpolate(
    torch.from_numpy(screenshot_np).permute(2, 0, 1).float().unsqueeze(0).to('cuda'),
    size=(416, 416), mode='bilinear', align_corners=False
).squeeze(0).permute(1, 2, 0).cpu().numpy().astype(np.uint8)
        
        try:
            # è½¬æ¢ä¸ºGPUå¼ é‡
            with torch.no_grad():
                # è½¬æ¢ä¸ºå¼ é‡å¹¶ç§»åˆ°GPU
                gpu_tensor = torch.from_numpy(screenshot_np).permute(2, 0, 1).float().to(self.device)
                
                # GPUä¸Šè°ƒæ•´å¤§å°
                resized = torch.nn.functional.interpolate(
                    gpu_tensor.unsqueeze(0),
                    size=(416, 416),
                    mode='bilinear',
                    align_corners=False
                )
                
                # è½¬å›CPU numpyæ•°ç»„
                result = resized.squeeze(0).permute(1, 2, 0).cpu().numpy().astype(np.uint8)
                
            return result
            
        except Exception as e:
            print(f"GPUé¢„å¤„ç†å¤±è´¥ï¼Œä½¿ç”¨CPU: {e}")
            return torch.nn.functional.interpolate(
    torch.from_numpy(screenshot_np).permute(2, 0, 1).float().unsqueeze(0).to('cuda'),
    size=(416, 416), mode='bilinear', align_corners=False
).squeeze(0).permute(1, 2, 0).cpu().numpy().astype(np.uint8)
    
    def optimized_capture_and_detect(self, fov_x, fov_y, fov_width, fov_height):
        """ä¼˜åŒ–çš„æ•è·å’Œæ£€æµ‹æµç¨‹"""
        # 1. å±å¹•æ•è·ï¼ˆCPUï¼‰
        with mss.mss() as sct:
            monitor = {
                "top": fov_y, 
                "left": fov_x, 
                "width": fov_width, 
                "height": fov_height
            }
            screenshot = sct.grab(monitor)
            screenshot_np = torch.tensor(screenshot, device='cuda').cpu().numpy()[:, :, :3]  # ç§»é™¤alphaé€šé“
        
        # 2. GPUå›¾åƒé¢„å¤„ç†
        processed_image = self.gpu_image_preprocessing(screenshot_np)
        
        # 3. GPUæ¨¡å‹æ¨ç†
        if self.model:
            with torch.no_grad():
                results = self.model.predict(
                    processed_image, 
                    device=self.device, 
                    verbose=False,
                    classes=[0, 1]  # enemyBody, enemyHead
                )
            return results
        
        return None
    
    def memory_efficient_detection_loop(self):
        """å†…å­˜é«˜æ•ˆçš„æ£€æµ‹å¾ªç¯"""
        # FOVè®¾ç½®
        screen_width = 1920  # æ ¹æ®ä½ çš„å±å¹•è°ƒæ•´
        screen_height = 1080
        fov_width = 320
        fov_height = 320
        fov_x = (screen_width - fov_width) // 2
        fov_y = (screen_height - fov_height) // 2
        
        print("ğŸ¯ å¼€å§‹GPUä¼˜åŒ–æ£€æµ‹å¾ªç¯...")
        print("æŒ‰Ctrl+Cåœæ­¢")
        
        frame_count = 0
        start_time = time.time()
        
        try:
            while True:
                # ä¼˜åŒ–çš„æ£€æµ‹
                results = self.optimized_capture_and_detect(fov_x, fov_y, fov_width, fov_height)
                
                # å¤„ç†ç»“æœ
                if results:
                    for r in results:
                        if r.boxes.xyxy.shape[0] > 0:
                            print(f"æ£€æµ‹åˆ° {r.boxes.xyxy.shape[0]} ä¸ªç›®æ ‡")
                        else:
                            print("ç›®æ ‡: âŒ")
                
                frame_count += 1
                
                # æ¯100å¸§æ˜¾ç¤ºæ€§èƒ½ç»Ÿè®¡
                if frame_count % 100 == 0:
                    elapsed = time.time() - start_time
                    fps = frame_count / elapsed
                    print(f"ğŸ“Š æ€§èƒ½ç»Ÿè®¡: {fps:.1f} FPS, GPUå†…å­˜: {torch.cuda.memory_allocated()/1024**2:.1f}MB")
                    
                    # æ¸…ç†GPUç¼“å­˜
                    if self.device.type == 'cuda':
                        torch.cuda.empty_cache()
                
                # å°å»¶è¿Ÿé¿å…100%CPUä½¿ç”¨
                time.sleep(0.001)
                
        except KeyboardInterrupt:
            print("\nğŸ›‘ æ£€æµ‹å¾ªç¯å·²åœæ­¢")
            
            # æœ€ç»ˆæ€§èƒ½æŠ¥å‘Š
            total_time = time.time() - start_time
            avg_fps = frame_count / total_time
            print(f"ğŸ“ˆ æœ€ç»ˆç»Ÿè®¡: å¹³å‡ {avg_fps:.1f} FPSï¼Œæ€»å¸§æ•°: {frame_count}")

def compare_cpu_vs_gpu():
    """CPU vs GPUæ€§èƒ½å¯¹æ¯”"""
    print("\nğŸ CPU vs GPU æ€§èƒ½å¯¹æ¯”")
    print("=" * 40)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    test_image = np.random.randint(0, 255, (320, 320, 3), dtype=np.uint8)
    
    # CPUæµ‹è¯•
    print("ğŸ–¥ï¸  CPUå¤„ç†æµ‹è¯•...")
    start_time = time.time()
    for _ in range(100):
        cpu_result = torch.nn.functional.interpolate(
    torch.from_numpy(test_image).permute(2, 0, 1).float().unsqueeze(0).to('cuda'),
    size=(416, 416), mode='bilinear', align_corners=False
).squeeze(0).permute(1, 2, 0).cpu().numpy().astype(np.uint8)
    cpu_time = time.time() - start_time
    
    # GPUæµ‹è¯•
    if torch.cuda.is_available():
        print("ğŸš€ GPUå¤„ç†æµ‹è¯•...")
        device = torch.device('cuda')
        
        start_time = time.time()
        for _ in range(100):
            with torch.no_grad():
                gpu_tensor = torch.from_numpy(test_image).permute(2, 0, 1).float().to(device)
                resized = torch.nn.functional.interpolate(
                    gpu_tensor.unsqueeze(0),
                    size=(416, 416),
                    mode='bilinear'
                )
                gpu_result = resized.squeeze(0).permute(1, 2, 0).cpu().numpy()
        
        torch.cuda.synchronize()
        gpu_time = time.time() - start_time
        
        print(f"ğŸ“Š ç»“æœå¯¹æ¯”:")
        print(f"   CPU: {cpu_time:.4f}s")
        print(f"   GPU: {gpu_time:.4f}s")
        print(f"   åŠ é€Ÿæ¯”: {cpu_time/gpu_time:.2f}x")
        
        if gpu_time < cpu_time:
            print("âœ… GPUæ›´å¿«ï¼Œå»ºè®®ä½¿ç”¨GPUå¤„ç†")
        else:
            print("âš ï¸  GPUè¾ƒæ…¢ï¼Œå¯èƒ½å› ä¸ºæ•°æ®ä¼ è¾“å¼€é”€")
    else:
        print("âŒ GPUä¸å¯ç”¨")

def memory_usage_tips():
    """å†…å­˜ä½¿ç”¨ä¼˜åŒ–å»ºè®®"""
    print("\nğŸ’¡ å†…å­˜ä¼˜åŒ–å»ºè®®")
    print("=" * 40)
    
    print("ğŸ”§ ç«‹å³å¯å®æ–½çš„ä¼˜åŒ–:")
    print("1. å°†YOLOv8æ¨¡å‹æ¨ç†ç§»åˆ°GPUï¼ˆå·²é…ç½®ï¼‰")
    print("2. å°†å›¾åƒé¢„å¤„ç†ç§»åˆ°GPU")
    print("3. ä½¿ç”¨torch.no_grad()å‡å°‘å†…å­˜å ç”¨")
    print("4. å®šæœŸæ¸…ç†GPUç¼“å­˜: torch.cuda.empty_cache()")
    
    print("\nâš¡ é«˜çº§ä¼˜åŒ–:")
    print("5. é¢„åˆ†é…GPUå†…å­˜ç¼“å†²åŒº")
    print("6. ä½¿ç”¨æ··åˆç²¾åº¦æ¨ç†ï¼ˆå¦‚æœç¨³å®šï¼‰")
    print("7. æ‰¹å¤„ç†å¤šå¸§å›¾åƒ")
    print("8. å¼‚æ­¥GPUæ“ä½œ")
    
    print("\nğŸ¯ é’ˆå¯¹ä½ çš„ç³»ç»Ÿï¼ˆå†…å­˜ä½¿ç”¨93.3%ï¼‰:")
    print("- ä¼˜å…ˆçº§1: ç«‹å³å¯ç”¨GPUå›¾åƒé¢„å¤„ç†")
    print("- ä¼˜å…ˆçº§2: å‡å°‘CPUå†…å­˜ä¸­çš„å›¾åƒç¼“å­˜")
    print("- ä¼˜å…ˆçº§3: ä½¿ç”¨GPUè¿›è¡Œæ‰€æœ‰è®¡ç®—å¯†é›†å‹æ“ä½œ")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ AI-Aimbot å†…å­˜åˆ°GPUè¿ç§»æ–¹æ¡ˆ")
    print("=" * 50)
    
    # 1. æ€§èƒ½å¯¹æ¯”
    compare_cpu_vs_gpu()
    
    # 2. å†…å­˜ä¼˜åŒ–å»ºè®®
    memory_usage_tips()
    
    # 3. å®é™…æµ‹è¯•ï¼ˆå¯é€‰ï¼‰
    print(f"\nğŸ¤– æ˜¯å¦è¦è¿è¡ŒGPUä¼˜åŒ–æµ‹è¯•ï¼Ÿ(y/n): ", end="")
    choice = input().lower().strip()
    
    if choice == 'y':
        optimizer = GPUOptimizedAimbot()
        if optimizer.model:
            print("âš ï¸  æ³¨æ„ï¼šè¿™å°†å¼€å§‹å®é™…æ£€æµ‹å¾ªç¯")
            print("ç¡®è®¤è¦ç»§ç»­å—ï¼Ÿ(y/n): ", end="")
            if input().lower().strip() == 'y':
                optimizer.memory_efficient_detection_loop()
        else:
            print("âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œæ— æ³•è¿è¡Œæµ‹è¯•")
    
    print("\nâœ… è¿ç§»æ–¹æ¡ˆå±•ç¤ºå®Œæˆï¼")

if __name__ == "__main__":
    main()