#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å†…å­˜å’ŒGPUä¼˜åŒ–å™¨
è§£å†³å†…å­˜ä¸è¶³ã€æ˜¾å­˜è¿‡é‡å’ŒåŒGPUåˆ©ç”¨ç‡é—®é¢˜
"""

import gc
import os
import sys
import psutil
import time
import onnxruntime as ort
import numpy as np
from typing import List, Dict, Any

class MemoryGPUOptimizer:
    """å†…å­˜å’ŒGPUä¼˜åŒ–å™¨"""
    
    def __init__(self):
        self.process = psutil.Process()
        self.initial_memory = self.get_memory_usage()
        self.gpu_providers = []
        self.optimized_session_options = None
        
    def get_memory_usage(self) -> Dict[str, float]:
        """è·å–å½“å‰å†…å­˜ä½¿ç”¨æƒ…å†µ"""
        memory_info = self.process.memory_info()
        system_memory = psutil.virtual_memory()
        
        return {
            'process_memory_mb': memory_info.rss / 1024 / 1024,
            'system_memory_percent': system_memory.percent,
            'system_available_gb': system_memory.available / 1024 / 1024 / 1024
        }
    
    def analyze_gpu_providers(self) -> List[str]:
        """åˆ†æå¯ç”¨çš„GPUæä¾›è€…"""
        available_providers = ort.get_available_providers()
        print(f"[INFO] å¯ç”¨çš„ONNXæä¾›è€…: {available_providers}")
        
        # ä¼˜å…ˆçº§æ’åºçš„æä¾›è€…åˆ—è¡¨
        priority_providers = [
            'CUDAExecutionProvider',    # NVIDIA GPU
            'DmlExecutionProvider',     # DirectML (AMD/Intel GPU)
            'CPUExecutionProvider'      # CPUå¤‡ç”¨
        ]
        
        # ç­›é€‰å¯ç”¨çš„æä¾›è€…
        self.gpu_providers = [p for p in priority_providers if p in available_providers]
        print(f"[INFO] ä¼˜å…ˆä½¿ç”¨çš„æä¾›è€…: {self.gpu_providers}")
        
        return self.gpu_providers
    
    def optimize_memory_usage(self):
        """ä¼˜åŒ–å†…å­˜ä½¿ç”¨"""
        print("[INFO] ğŸ§¹ å¼€å§‹å†…å­˜ä¼˜åŒ–...")
        
        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        collected = gc.collect()
        print(f"[INFO] åƒåœ¾å›æ”¶é‡Šæ”¾äº† {collected} ä¸ªå¯¹è±¡")
        
        # è®¾ç½®ç¯å¢ƒå˜é‡ä¼˜åŒ–å†…å­˜
        os.environ['OMP_NUM_THREADS'] = '16'  # ä¼˜åŒ–OpenMPçº¿ç¨‹æ•°ï¼ˆ32æ ¸CPUï¼‰
os.environ['MKL_NUM_THREADS'] = '16'  # ä¼˜åŒ–MKLçº¿ç¨‹æ•°
os.environ['NUMEXPR_NUM_THREADS'] = '16'  # ä¼˜åŒ–NumExprçº¿ç¨‹æ•°
        
        # ä¼˜åŒ–NumPyå†…å­˜ä½¿ç”¨
        np.seterr(all='ignore')  # å¿½ç•¥æ•°å€¼è­¦å‘Šä»¥å‡å°‘å†…å­˜å¼€é”€
        
        print("[INFO] âœ… å†…å­˜ä¼˜åŒ–å®Œæˆ")
    
    def create_optimized_session_options(self) -> ort.SessionOptions:
        """åˆ›å»ºä¼˜åŒ–çš„ONNXä¼šè¯é€‰é¡¹"""
        print("[INFO] âš™ï¸ åˆ›å»ºä¼˜åŒ–çš„ONNXä¼šè¯é€‰é¡¹...")
        
        so = ort.SessionOptions()
        
        # å›¾ä¼˜åŒ–è®¾ç½®
        so.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL
        
        # å†…å­˜ä¼˜åŒ–è®¾ç½®
        so.enable_mem_pattern = True
        so.enable_cpu_mem_arena = True
        
        # çº¿ç¨‹è®¾ç½®ï¼ˆå‡å°‘å†…å­˜å ç”¨ï¼‰
        so.intra_op_num_threads = 16  # ä¼˜åŒ–çº¿ç¨‹æ•°ä»¥å……åˆ†åˆ©ç”¨32æ ¸CPU
        so.inter_op_num_threads = 8   # å¢åŠ å¹¶è¡Œæ“ä½œçº¿ç¨‹æ•°
        
        # æ‰§è¡Œæ¨¡å¼è®¾ç½®
        so.execution_mode = ort.ExecutionMode.ORT_SEQUENTIAL  # é¡ºåºæ‰§è¡Œä»¥èŠ‚çœå†…å­˜
        
        self.optimized_session_options = so
        print("[INFO] âœ… ONNXä¼šè¯é€‰é¡¹ä¼˜åŒ–å®Œæˆ")
        
        return so
    
    def create_dual_gpu_sessions(self, model_path: str) -> Dict[str, Any]:
        """åˆ›å»ºåŒGPUä¼šè¯é…ç½®"""
        print("[INFO] ğŸ”„ é…ç½®åŒGPUè´Ÿè½½å‡è¡¡...")
        
        sessions = {}
        
        try:
            # è·å–ä¼˜åŒ–çš„ä¼šè¯é€‰é¡¹
            so = self.create_optimized_session_options()
            
            # å°è¯•åˆ›å»ºNVIDIA GPUä¼šè¯
            if 'CUDAExecutionProvider' in self.gpu_providers:
                cuda_options = {
                    'device_id': 0,  # ä½¿ç”¨ç¬¬ä¸€ä¸ªNVIDIA GPU
                    'arena_extend_strategy': 'kNextPowerOfTwo',  # æ›´æ¿€è¿›çš„å†…å­˜ç­–ç•¥
                    'gpu_mem_limit': 6 * 1024 * 1024 * 1024,  # é™åˆ¶GPUå†…å­˜ä¸º6GBï¼ˆRTX 4060é€‚é…ï¼‰
                    'cudnn_conv_algo_search': 'EXHAUSTIVE',
                    'do_copy_in_default_stream': True,  # å¯ç”¨é»˜è®¤æµå¤åˆ¶
                    'cudnn_conv_use_max_workspace': True,  # ä½¿ç”¨æœ€å¤§å·¥ä½œç©ºé—´
                }
                
                sessions['nvidia'] = ort.InferenceSession(
                    model_path,
                    sess_options=so,
                    providers=[('CUDAExecutionProvider', cuda_options)]
                )
                print("[INFO] âœ… NVIDIA GPUä¼šè¯åˆ›å»ºæˆåŠŸ")
            
            # å°è¯•åˆ›å»ºAMD GPUä¼šè¯
            if 'DmlExecutionProvider' in self.gpu_providers:
                dml_options = {
                    'device_id': 1,  # å°è¯•ä½¿ç”¨ç¬¬äºŒä¸ªGPU
                }
                
                sessions['amd'] = ort.InferenceSession(
                    model_path,
                    sess_options=so,
                    providers=[('DmlExecutionProvider', dml_options)]
                )
                print("[INFO] âœ… AMD GPUä¼šè¯åˆ›å»ºæˆåŠŸ")
            
            # CPUå¤‡ç”¨ä¼šè¯
            sessions['cpu'] = ort.InferenceSession(
                model_path,
                sess_options=so,
                providers=['CPUExecutionProvider']
            )
            print("[INFO] âœ… CPUå¤‡ç”¨ä¼šè¯åˆ›å»ºæˆåŠŸ")
            
        except Exception as e:
            print(f"[ERROR] åˆ›å»ºGPUä¼šè¯å¤±è´¥: {e}")
            # åˆ›å»ºCPUå¤‡ç”¨ä¼šè¯
            sessions['cpu'] = ort.InferenceSession(
                model_path,
                sess_options=self.create_optimized_session_options(),
                providers=['CPUExecutionProvider']
            )
        
        return sessions
    
    def optimize_vram_usage(self) -> Dict[str, Any]:
        """ä¼˜åŒ–æ˜¾å­˜ä½¿ç”¨é…ç½®"""
        print("[INFO] ğŸ’¾ ä¼˜åŒ–æ˜¾å­˜ä½¿ç”¨é…ç½®...")
        
        vram_config = {
            # CUDAé…ç½®
            'cuda_options': {
                'arena_extend_strategy': 'kNextPowerOfTwo',  # æ›´æ¿€è¿›çš„å†…å­˜åˆ†é…
                'gpu_mem_limit': 6 * 1024 * 1024 * 1024,  # é™åˆ¶ä¸º6GBï¼ˆRTX 4060é€‚é…ï¼‰
                'cudnn_conv_algo_search': 'EXHAUSTIVE',  # ä½¿ç”¨æœ€ä¼˜ç®—æ³•
                'do_copy_in_default_stream': True,
                'cudnn_conv_use_max_workspace': True,  # ä½¿ç”¨æœ€å¤§å·¥ä½œç©ºé—´
            },
            
            # DirectMLé…ç½®
            'dml_options': {
                'device_id': 1,  # ä½¿ç”¨ç¬¬äºŒä¸ªGPU
            },
            
            # ä¼šè¯é…ç½®
            'session_options': {
                'enable_mem_pattern': True,
                'enable_cpu_mem_arena': True,
                'execution_mode': 'sequential',
                'intra_op_num_threads': 4,
                'inter_op_num_threads': 2,
            }
        }
        
        print("[INFO] âœ… æ˜¾å­˜ä¼˜åŒ–é…ç½®å®Œæˆ")
        return vram_config
    
    def monitor_performance(self, duration: int = 10):
        """ç›‘æ§æ€§èƒ½æŒ‡æ ‡"""
        print(f"[INFO] ğŸ“Š å¼€å§‹ç›‘æ§æ€§èƒ½ ({duration}ç§’)...")
        
        start_time = time.time()
        memory_samples = []
        
        while time.time() - start_time < duration:
            memory_info = self.get_memory_usage()
            memory_samples.append(memory_info)
            time.sleep(1)
        
        # è®¡ç®—å¹³å‡å€¼
        avg_memory = {
            'process_memory_mb': sum(s['process_memory_mb'] for s in memory_samples) / len(memory_samples),
            'system_memory_percent': sum(s['system_memory_percent'] for s in memory_samples) / len(memory_samples),
            'system_available_gb': sum(s['system_available_gb'] for s in memory_samples) / len(memory_samples)
        }
        
        print(f"[INFO] ğŸ“ˆ å¹³å‡å†…å­˜ä½¿ç”¨:")
        print(f"  - è¿›ç¨‹å†…å­˜: {avg_memory['process_memory_mb']:.1f} MB")
        print(f"  - ç³»ç»Ÿå†…å­˜: {avg_memory['system_memory_percent']:.1f}%")
        print(f"  - å¯ç”¨å†…å­˜: {avg_memory['system_available_gb']:.1f} GB")
        
        return avg_memory
    
    def generate_optimized_config(self) -> str:
        """ç”Ÿæˆä¼˜åŒ–é…ç½®ä»£ç """
        config_code = '''
# ä¼˜åŒ–çš„ONNXé…ç½®
import onnxruntime as ort
import os

# è®¾ç½®ç¯å¢ƒå˜é‡ä¼˜åŒ–å†…å­˜
os.environ['OMP_NUM_THREADS'] = '4'
os.environ['MKL_NUM_THREADS'] = '4'
os.environ['NUMEXPR_NUM_THREADS'] = '4'

def create_optimized_onnx_session(model_path, use_dual_gpu=True):
    """åˆ›å»ºä¼˜åŒ–çš„ONNXä¼šè¯"""
    
    # ä¼˜åŒ–çš„ä¼šè¯é€‰é¡¹
    so = ort.SessionOptions()
    so.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL
    so.enable_mem_pattern = True
    so.enable_cpu_mem_arena = True
    so.intra_op_num_threads = 4
    so.inter_op_num_threads = 2
    so.execution_mode = ort.ExecutionMode.ORT_SEQUENTIAL
    
    # æä¾›è€…é…ç½®
    providers = []
    
    # NVIDIA GPUé…ç½®ï¼ˆä¼˜åŒ–æ˜¾å­˜ä½¿ç”¨ï¼‰
    cuda_options = {
        'device_id': 0,
        'arena_extend_strategy': 'kNextPowerOfTwo',  # æ›´æ¿€è¿›çš„å†…å­˜åˆ†é…
        'gpu_mem_limit': 6 * 1024 * 1024 * 1024,  # 6GBé™åˆ¶ï¼ˆRTX 4060é€‚é…ï¼‰
        'cudnn_conv_algo_search': 'EXHAUSTIVE',  # ä½¿ç”¨æœ€ä¼˜ç®—æ³•
        'do_copy_in_default_stream': True,  # å¯ç”¨é»˜è®¤æµå¤åˆ¶
        'cudnn_conv_use_max_workspace': True,  # ä½¿ç”¨æœ€å¤§å·¥ä½œç©ºé—´
    }
    providers.append(('CUDAExecutionProvider', cuda_options))
    
    # AMD GPUé…ç½®ï¼ˆå¦‚æœéœ€è¦åŒGPUï¼‰
    if use_dual_gpu:
        dml_options = {'device_id': 1}
        providers.append(('DmlExecutionProvider', dml_options))
    
    # CPUå¤‡ç”¨
    providers.append('CPUExecutionProvider')
    
    try:
        session = ort.InferenceSession(model_path, sess_options=so, providers=providers)
        print(f"[INFO] ONNXä¼šè¯åˆ›å»ºæˆåŠŸï¼Œä½¿ç”¨æä¾›è€…: {session.get_providers()}")
        return session
    except Exception as e:
        print(f"[ERROR] ONNXä¼šè¯åˆ›å»ºå¤±è´¥: {e}")
        # å¤‡ç”¨CPUä¼šè¯
        return ort.InferenceSession(model_path, sess_options=so, providers=['CPUExecutionProvider'])
'''
        return config_code
    
    def run_optimization(self, model_path: str = 'yolov5s320Half.onnx'):
        """è¿è¡Œå®Œæ•´ä¼˜åŒ–æµç¨‹"""
        print("=" * 60)
        print("ğŸš€ AI-Aimbot å†…å­˜å’ŒGPUä¼˜åŒ–å™¨")
        print("=" * 60)
        
        # 1. åˆ†æåˆå§‹çŠ¶æ€
        print("\nğŸ“Š åˆå§‹çŠ¶æ€åˆ†æ:")
        initial_memory = self.get_memory_usage()
        print(f"  - è¿›ç¨‹å†…å­˜: {initial_memory['process_memory_mb']:.1f} MB")
        print(f"  - ç³»ç»Ÿå†…å­˜: {initial_memory['system_memory_percent']:.1f}%")
        print(f"  - å¯ç”¨å†…å­˜: {initial_memory['system_available_gb']:.1f} GB")
        
        # 2. åˆ†æGPUæä¾›è€…
        print("\nğŸ” GPUæä¾›è€…åˆ†æ:")
        self.analyze_gpu_providers()
        
        # 3. ä¼˜åŒ–å†…å­˜ä½¿ç”¨
        print("\nğŸ§¹ å†…å­˜ä¼˜åŒ–:")
        self.optimize_memory_usage()
        
        # 4. ä¼˜åŒ–æ˜¾å­˜é…ç½®
        print("\nğŸ’¾ æ˜¾å­˜ä¼˜åŒ–:")
        vram_config = self.optimize_vram_usage()
        
        # 5. åˆ›å»ºä¼˜åŒ–é…ç½®
        print("\nâš™ï¸ ç”Ÿæˆä¼˜åŒ–é…ç½®:")
        config_code = self.generate_optimized_config()
        
        # ä¿å­˜ä¼˜åŒ–é…ç½®åˆ°æ–‡ä»¶
        with open('optimized_onnx_config.py', 'w', encoding='utf-8') as f:
            f.write(config_code)
        print("[INFO] âœ… ä¼˜åŒ–é…ç½®å·²ä¿å­˜åˆ° optimized_onnx_config.py")
        
        # 6. æœ€ç»ˆçŠ¶æ€æ£€æŸ¥
        print("\nğŸ“ˆ ä¼˜åŒ–åçŠ¶æ€:")
        final_memory = self.get_memory_usage()
        print(f"  - è¿›ç¨‹å†…å­˜: {final_memory['process_memory_mb']:.1f} MB")
        print(f"  - ç³»ç»Ÿå†…å­˜: {final_memory['system_memory_percent']:.1f}%")
        print(f"  - å¯ç”¨å†…å­˜: {final_memory['system_available_gb']:.1f} GB")
        
        # è®¡ç®—æ”¹å–„æƒ…å†µ
        memory_improvement = initial_memory['system_memory_percent'] - final_memory['system_memory_percent']
        print(f"\nâœ¨ å†…å­˜ä½¿ç”¨æ”¹å–„: {memory_improvement:.1f}%")
        
        print("\n" + "=" * 60)
        print("ğŸ¯ ä¼˜åŒ–å»ºè®®:")
        print("1. ä½¿ç”¨ç”Ÿæˆçš„ optimized_onnx_config.py æ›¿æ¢ç°æœ‰ONNXé…ç½®")
        print("2. é‡å¯AI-Aimbotä»¥åº”ç”¨ä¼˜åŒ–è®¾ç½®")
        print("3. ç›‘æ§GPUåˆ©ç”¨ç‡ç¡®è®¤åŒGPUå·¥ä½œçŠ¶æ€")
        print("4. å¦‚æœå†…å­˜ä»ç„¶ä¸è¶³ï¼Œè€ƒè™‘é™ä½æˆªå›¾åˆ†è¾¨ç‡")
        print("=" * 60)

def main():
    """ä¸»å‡½æ•°"""
    optimizer = MemoryGPUOptimizer()
    optimizer.run_optimization()

if __name__ == "__main__":
    main()