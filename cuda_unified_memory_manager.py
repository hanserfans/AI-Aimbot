#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CUDAç»Ÿä¸€å†…å­˜ç®¡ç†å™¨
å®ç°CUDAç»Ÿä¸€å†…å­˜ï¼ˆUnified Memoryï¼‰æ”¯æŒ
è‡ªåŠ¨CPU-GPUå†…å­˜è¿ç§»ï¼Œç®€åŒ–å†…å­˜ç®¡ç†ï¼Œæå‡æ€§èƒ½
"""

import torch
import numpy as np
import time
import gc
import ctypes
from typing import Dict, List, Tuple, Optional, Any, Union
from collections import defaultdict
import threading
import psutil
import warnings

# å°è¯•å¯¼å…¥CUDAè¿è¡Œæ—¶API
try:
    import cupy as cp
    CUPY_AVAILABLE = True
except ImportError:
    CUPY_AVAILABLE = False
    print("[WARNING] CuPyæœªå®‰è£…ï¼Œéƒ¨åˆ†ç»Ÿä¸€å†…å­˜åŠŸèƒ½å°†å—é™")

class CUDAUnifiedMemoryManager:
    """CUDAç»Ÿä¸€å†…å­˜ç®¡ç†å™¨ - å®ç°CPUå’ŒGPUé—´çš„ç»Ÿä¸€å†…å­˜ç©ºé—´"""
    
    def __init__(self, device_ids: List[int] = [0], unified_pool_size_gb: float = 2.0):
        """
        åˆå§‹åŒ–CUDAç»Ÿä¸€å†…å­˜ç®¡ç†å™¨
        
        Args:
            device_ids: GPUè®¾å¤‡IDåˆ—è¡¨
            unified_pool_size_gb: ç»Ÿä¸€å†…å­˜æ± å¤§å°(GB)
        """
        self.device_ids = device_ids
        self.unified_pool_size_bytes = int(unified_pool_size_gb * 1024**3)
        self.devices = [f'cuda:{i}' for i in device_ids if torch.cuda.is_available()]
        
        if not self.devices:
            self.devices = ['cpu']
            print("[WARNING] æ— å¯ç”¨GPUï¼Œç»Ÿä¸€å†…å­˜åŠŸèƒ½å°†å—é™")
            
        # æ£€æŸ¥ç»Ÿä¸€å†…å­˜æ”¯æŒ
        self.unified_memory_supported = self._check_unified_memory_support()
        
        # ç»Ÿä¸€å†…å­˜æ± 
        self.unified_memory_pool = {}
        self.unified_memory_usage = {}
        self.unified_memory_locks = {}
        
        # ä¼ ç»Ÿå†…å­˜æ± ï¼ˆä½œä¸ºå¤‡ç”¨ï¼‰
        self.fallback_memory_pool = {}
        self.fallback_usage = {}
        
        # å†…å­˜è®¿é—®æ¨¡å¼è·Ÿè¸ª
        self.access_patterns = defaultdict(list)
        self.migration_stats = {
            'cpu_to_gpu_migrations': 0,
            'gpu_to_cpu_migrations': 0,
            'automatic_migrations': 0,
            'manual_migrations': 0,
            'migration_time_total': 0.0
        }
        
        # æ€§èƒ½ç»Ÿè®¡
        self.stats = {
            'unified_allocations': 0,
            'fallback_allocations': 0,
            'memory_saved_bytes': 0,
            'access_violations': 0,
            'prefetch_hits': 0,
            'prefetch_misses': 0
        }
        
        # åˆå§‹åŒ–ç»Ÿä¸€å†…å­˜æ± 
        self._initialize_unified_memory_pools()
        
        print(f"[INFO] ğŸŒ CUDAç»Ÿä¸€å†…å­˜ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"[INFO] è®¾å¤‡: {self.devices}")
        print(f"[INFO] ç»Ÿä¸€å†…å­˜æ”¯æŒ: {'âœ…' if self.unified_memory_supported else 'âŒ'}")
        print(f"[INFO] ç»Ÿä¸€å†…å­˜æ± å¤§å°: {unified_pool_size_gb:.1f}GB")
        
    def _check_unified_memory_support(self) -> bool:
        """æ£€æŸ¥GPUæ˜¯å¦æ”¯æŒç»Ÿä¸€å†…å­˜"""
        if not torch.cuda.is_available():
            return False
            
        try:
            # æ£€æŸ¥GPUæ¶æ„ï¼ˆPascalåŠä»¥ä¸Šæ”¯æŒç¡¬ä»¶ç»Ÿä¸€å†…å­˜ï¼‰
            for device_id in self.device_ids:
                props = torch.cuda.get_device_properties(device_id)
                major, minor = props.major, props.minor
                
                # Pascal (6.0+), Volta (7.0+), Turing (7.5+), Ampere (8.0+)
                if major >= 6:
                    print(f"[INFO] ğŸ¯ GPU {device_id} ({props.name}) æ”¯æŒç¡¬ä»¶ç»Ÿä¸€å†…å­˜ (è®¡ç®—èƒ½åŠ› {major}.{minor})")
                    return True
                else:
                    print(f"[WARNING] GPU {device_id} ({props.name}) ä¸æ”¯æŒç¡¬ä»¶ç»Ÿä¸€å†…å­˜ (è®¡ç®—èƒ½åŠ› {major}.{minor})")
                    
            return False
            
        except Exception as e:
            print(f"[WARNING] æ£€æŸ¥ç»Ÿä¸€å†…å­˜æ”¯æŒæ—¶å‡ºé”™: {e}")
            return False
            
    def _initialize_unified_memory_pools(self):
        """åˆå§‹åŒ–ç»Ÿä¸€å†…å­˜æ± """
        for device in self.devices:
            if device == 'cpu':
                continue
                
            try:
                self.unified_memory_pool[device] = {}
                self.unified_memory_usage[device] = {}
                self.unified_memory_locks[device] = threading.Lock()
                
                self.fallback_memory_pool[device] = {}
                self.fallback_usage[device] = {}
                
                # é¢„åˆ†é…å¸¸ç”¨å°ºå¯¸çš„ç»Ÿä¸€å†…å­˜å—
                if self.unified_memory_supported:
                    common_sizes = [
                        (1, 3, 320, 320),    # æ ‡å‡†æ£€æµ‹å›¾åƒ
                        (1, 3, 640, 640),    # é«˜åˆ†è¾¨ç‡æ£€æµ‹
                        (320, 320, 3),       # å¤„ç†åå›¾åƒ
                        (100, 6),            # æ£€æµ‹ç»“æœ
                    ]
                    
                    for size in common_sizes:
                        self._preallocate_unified_buffer(device, size)
                        
                    print(f"[INFO] ğŸŒ {device} ç»Ÿä¸€å†…å­˜æ± åˆå§‹åŒ–å®Œæˆï¼Œé¢„åˆ†é…{len(common_sizes)}ä¸ªç¼“å†²åŒº")
                else:
                    print(f"[INFO] ğŸ“¦ {device} ä½¿ç”¨ä¼ ç»Ÿå†…å­˜æ± æ¨¡å¼")
                    
            except Exception as e:
                print(f"[WARNING] {device} ç»Ÿä¸€å†…å­˜æ± åˆå§‹åŒ–å¤±è´¥: {e}")
                
    def _preallocate_unified_buffer(self, device: str, size: Tuple, dtype=torch.float16):
        """é¢„åˆ†é…ç»Ÿä¸€å†…å­˜ç¼“å†²åŒº"""
        try:
            key = f"{size}_{dtype}"
            
            if self.unified_memory_supported:
                # åˆ›å»ºç»Ÿä¸€å†…å­˜å¼ é‡
                buffer = self._allocate_unified_tensor(size, dtype, device)
            else:
                # å›é€€åˆ°ä¼ ç»Ÿå†…å­˜
                buffer = torch.empty(size, dtype=dtype, device=device)
                
            with self.unified_memory_locks[device]:
                self.unified_memory_pool[device][key] = buffer
                self.unified_memory_usage[device][key] = False
                
        except Exception as e:
            print(f"[WARNING] é¢„åˆ†é…ç»Ÿä¸€å†…å­˜ç¼“å†²åŒºå¤±è´¥ {device} {size}: {e}")
            
    def _allocate_unified_tensor(self, size: Tuple, dtype=torch.float16, device: str = None) -> torch.Tensor:
        """åˆ†é…ç»Ÿä¸€å†…å­˜å¼ é‡"""
        if not self.unified_memory_supported:
            return torch.empty(size, dtype=dtype, device=device)
            
        try:
            # æ–¹æ³•1: ä½¿ç”¨PyTorchçš„ç»Ÿä¸€å†…å­˜åˆ†é…ï¼ˆå¦‚æœæ”¯æŒï¼‰
            if hasattr(torch.cuda, 'memory_pool'):
                # å°è¯•ä½¿ç”¨å†…å­˜æ± åˆ†é…ç»Ÿä¸€å†…å­˜
                with torch.cuda.device(device):
                    tensor = torch.empty(size, dtype=dtype, device='cuda', memory_format=torch.contiguous_format)
                    # æ ‡è®°ä¸ºç»Ÿä¸€å†…å­˜ï¼ˆå¦‚æœAPIæ”¯æŒï¼‰
                    return tensor
                    
            # æ–¹æ³•2: ä½¿ç”¨CuPyåˆ†é…ç»Ÿä¸€å†…å­˜
            elif CUPY_AVAILABLE:
                with cp.cuda.Device(int(device.split(':')[1])):
                    # è®¡ç®—æ‰€éœ€çš„å­—èŠ‚æ•°
                    element_count = np.prod(size)
                    dtype_size = np.dtype(np.float16).itemsize
                    total_bytes = element_count * dtype_size
                    
                    print(f"[DEBUG] CuPyç»Ÿä¸€å†…å­˜åˆ†é…: size={size}, elements={element_count}, bytes={total_bytes}")
                    
                    # åˆ†é…ç»Ÿä¸€å†…å­˜
                    cupy_array = cp.cuda.alloc_pinned_memory(total_bytes)
                    
                    # éªŒè¯åˆ†é…çš„å†…å­˜å¤§å°
                    buffer_size = len(cupy_array)
                    expected_size = element_count * dtype_size
                    
                    if buffer_size != expected_size:
                        raise ValueError(f"å†…å­˜åˆ†é…å¤§å°ä¸åŒ¹é…: åˆ†é…äº†{buffer_size}å­—èŠ‚ï¼ŒæœŸæœ›{expected_size}å­—èŠ‚")
                    
                    # è½¬æ¢ä¸ºPyTorchå¼ é‡
                    try:
                        numpy_array = np.frombuffer(cupy_array, dtype=np.float16)
                        print(f"[DEBUG] numpy_arrayå½¢çŠ¶: {numpy_array.shape}, æœŸæœ›å…ƒç´ æ•°: {element_count}")
                        
                        if numpy_array.size != element_count:
                            raise ValueError(f"æ•°ç»„å…ƒç´ æ•°ä¸åŒ¹é…: å®é™…{numpy_array.size}ï¼ŒæœŸæœ›{element_count}")
                        
                        tensor = torch.from_numpy(numpy_array.reshape(size))
                        return tensor.to(device)
                        
                    except Exception as reshape_error:
                        print(f"[ERROR] CuPyå¼ é‡é‡å¡‘å¤±è´¥: {reshape_error}")
                        print(f"[ERROR] ç¼“å†²åŒºå¤§å°: {buffer_size}, æ•°ç»„å¤§å°: {numpy_array.size if 'numpy_array' in locals() else 'N/A'}")
                        raise
                    
            # æ–¹æ³•3: å›é€€åˆ°å›ºå®šå†…å­˜ + å¼‚æ­¥ä¼ è¾“
            else:
                # åˆ›å»ºCPUå›ºå®šå†…å­˜
                cpu_tensor = torch.empty(size, dtype=dtype).pin_memory()
                # å¼‚æ­¥ä¼ è¾“åˆ°GPU
                gpu_tensor = cpu_tensor.to(device, non_blocking=True)
                return gpu_tensor
                
        except Exception as e:
            print(f"[WARNING] ç»Ÿä¸€å†…å­˜åˆ†é…å¤±è´¥ï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•: {e}")
            return torch.empty(size, dtype=dtype, device=device)
            
    def allocate_unified_memory(self, size: Tuple, dtype=torch.float16, device: str = None, 
                              access_pattern: str = 'mixed') -> torch.Tensor:
        """
        åˆ†é…ç»Ÿä¸€å†…å­˜å¼ é‡
        
        Args:
            size: å¼ é‡å°ºå¯¸
            dtype: æ•°æ®ç±»å‹
            device: ç›®æ ‡è®¾å¤‡
            access_pattern: è®¿é—®æ¨¡å¼ ('cpu_heavy', 'gpu_heavy', 'mixed')
            
        Returns:
            ç»Ÿä¸€å†…å­˜å¼ é‡
        """
        if device is None:
            device = self.devices[0]
            
        key = f"{size}_{dtype}"
        
        # å°è¯•ä»ç»Ÿä¸€å†…å­˜æ± è·å–
        if device in self.unified_memory_pool:
            with self.unified_memory_locks[device]:
                if key in self.unified_memory_pool[device] and not self.unified_memory_usage[device].get(key, True):
                    self.unified_memory_usage[device][key] = True
                    self.stats['unified_allocations'] += 1
                    
                    # è®°å½•è®¿é—®æ¨¡å¼
                    self.access_patterns[key].append(access_pattern)
                    
                    return self.unified_memory_pool[device][key]
        
        # åˆ›å»ºæ–°çš„ç»Ÿä¸€å†…å­˜å¼ é‡
        try:
            print(f"[DEBUG] å°è¯•åˆ†é…ç»Ÿä¸€å†…å­˜: size={size}, dtype={dtype}, device={device}")
            tensor = self._allocate_unified_tensor(size, dtype, device)
            self.stats['unified_allocations'] += 1
            
            # æ ¹æ®è®¿é—®æ¨¡å¼è¿›è¡Œé¢„å–
            self._prefetch_memory(tensor, access_pattern, device)
            
            print(f"[DEBUG] ç»Ÿä¸€å†…å­˜åˆ†é…æˆåŠŸ: {tensor.shape}, device={tensor.device}")
            return tensor
            
        except torch.cuda.OutOfMemoryError as oom_error:
            print(f"[WARNING] GPUå†…å­˜ä¸è¶³ï¼Œå°è¯•æ¸…ç†åé‡è¯•: {oom_error}")
            # å†…å­˜ä¸è¶³æ—¶æ¸…ç†å¹¶é‡è¯•
            self._emergency_cleanup(device)
            try:
                tensor = self._allocate_unified_tensor(size, dtype, device)
                self.stats['fallback_allocations'] += 1
                print(f"[INFO] æ¸…ç†åé‡è¯•æˆåŠŸ")
                return tensor
            except Exception as retry_error:
                print(f"[ERROR] æ¸…ç†åé‡è¯•ä»å¤±è´¥: {retry_error}")
                raise
                
        except ValueError as value_error:
            print(f"[ERROR] ç»Ÿä¸€å†…å­˜åˆ†é…å‚æ•°é”™è¯¯: {value_error}")
            print(f"[ERROR] å‚æ•°ä¿¡æ¯: size={size}, dtype={dtype}, device={device}")
            # å¯¹äºreshapeç­‰é”™è¯¯ï¼Œç›´æ¥å›é€€åˆ°ä¼ ç»Ÿå†…å­˜
            print(f"[INFO] å›é€€åˆ°ä¼ ç»ŸGPUå†…å­˜åˆ†é…")
            fallback_tensor = torch.empty(size, dtype=dtype, device=device)
            self.stats['fallback_allocations'] += 1
            return fallback_tensor
            
        except Exception as general_error:
            print(f"[ERROR] ç»Ÿä¸€å†…å­˜åˆ†é…å¤±è´¥: {general_error}")
            print(f"[ERROR] é”™è¯¯ç±»å‹: {type(general_error).__name__}")
            print(f"[INFO] å›é€€åˆ°ä¼ ç»ŸGPUå†…å­˜åˆ†é…")
            # å›é€€åˆ°ä¼ ç»ŸGPUå†…å­˜
            try:
                fallback_tensor = torch.empty(size, dtype=dtype, device=device)
                self.stats['fallback_allocations'] += 1
                return fallback_tensor
            except Exception as fallback_error:
                print(f"[CRITICAL] ä¼ ç»Ÿå†…å­˜åˆ†é…ä¹Ÿå¤±è´¥: {fallback_error}")
                raise RuntimeError(f"æ‰€æœ‰å†…å­˜åˆ†é…æ–¹æ³•éƒ½å¤±è´¥: ç»Ÿä¸€å†…å­˜({general_error}), ä¼ ç»Ÿå†…å­˜({fallback_error})")
            
    def _prefetch_memory(self, tensor: torch.Tensor, access_pattern: str, device: str):
        """æ ¹æ®è®¿é—®æ¨¡å¼é¢„å–å†…å­˜"""
        if not self.unified_memory_supported:
            return
            
        try:
            if access_pattern == 'gpu_heavy':
                # é¢„å–åˆ°GPU
                if hasattr(torch.cuda, 'memory_advise'):
                    torch.cuda.memory_advise(tensor, 'PREFERRED_LOCATION', device)
                self.stats['prefetch_hits'] += 1
                
            elif access_pattern == 'cpu_heavy':
                # é¢„å–åˆ°CPU
                if hasattr(torch.cuda, 'memory_advise'):
                    torch.cuda.memory_advise(tensor, 'PREFERRED_LOCATION', 'cpu')
                self.stats['prefetch_hits'] += 1
                
            # mixedæ¨¡å¼ä¸è¿›è¡Œé¢„å–ï¼Œè®©ç³»ç»Ÿè‡ªåŠ¨ç®¡ç†
            
        except Exception as e:
            print(f"[WARNING] å†…å­˜é¢„å–å¤±è´¥: {e}")
            self.stats['prefetch_misses'] += 1
            
    def migrate_to_device(self, tensor: torch.Tensor, target_device: str, 
                         async_migration: bool = True) -> torch.Tensor:
        """
        æ‰‹åŠ¨è¿ç§»ç»Ÿä¸€å†…å­˜åˆ°æŒ‡å®šè®¾å¤‡
        
        Args:
            tensor: æºå¼ é‡
            target_device: ç›®æ ‡è®¾å¤‡
            async_migration: æ˜¯å¦å¼‚æ­¥è¿ç§»
            
        Returns:
            è¿ç§»åçš„å¼ é‡
        """
        start_time = time.time()
        
        try:
            if async_migration:
                migrated_tensor = tensor.to(target_device, non_blocking=True)
            else:
                migrated_tensor = tensor.to(target_device)
                
            # æ›´æ–°è¿ç§»ç»Ÿè®¡
            migration_time = time.time() - start_time
            self.migration_stats['migration_time_total'] += migration_time
            self.migration_stats['manual_migrations'] += 1
            
            if 'cpu' in str(tensor.device) and 'cuda' in target_device:
                self.migration_stats['cpu_to_gpu_migrations'] += 1
            elif 'cuda' in str(tensor.device) and 'cpu' in target_device:
                self.migration_stats['gpu_to_cpu_migrations'] += 1
                
            return migrated_tensor
            
        except Exception as e:
            print(f"[WARNING] å†…å­˜è¿ç§»å¤±è´¥: {e}")
            return tensor
            
    def optimize_access_patterns(self):
        """åŸºäºè®¿é—®æ¨¡å¼ä¼˜åŒ–å†…å­˜å¸ƒå±€"""
        print("[INFO] ğŸ”„ å¼€å§‹ä¼˜åŒ–å†…å­˜è®¿é—®æ¨¡å¼...")
        
        for key, patterns in self.access_patterns.items():
            if len(patterns) < 5:  # æ ·æœ¬å¤ªå°‘ï¼Œè·³è¿‡
                continue
                
            # åˆ†æè®¿é—®æ¨¡å¼
            gpu_heavy_count = patterns.count('gpu_heavy')
            cpu_heavy_count = patterns.count('cpu_heavy')
            mixed_count = patterns.count('mixed')
            
            total_count = len(patterns)
            gpu_ratio = gpu_heavy_count / total_count
            cpu_ratio = cpu_heavy_count / total_count
            
            # æ ¹æ®è®¿é—®æ¨¡å¼è°ƒæ•´å†…å­˜ä½ç½®
            if gpu_ratio > 0.7:
                print(f"[INFO] ğŸ“Š {key} ä¸»è¦åœ¨GPUè®¿é—® ({gpu_ratio:.1%})ï¼Œä¼˜åŒ–GPUäº²å’Œæ€§")
                # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ GPUäº²å’Œæ€§ä¼˜åŒ–
            elif cpu_ratio > 0.7:
                print(f"[INFO] ğŸ“Š {key} ä¸»è¦åœ¨CPUè®¿é—® ({cpu_ratio:.1%})ï¼Œä¼˜åŒ–CPUäº²å’Œæ€§")
                # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ CPUäº²å’Œæ€§ä¼˜åŒ–
            else:
                print(f"[INFO] ğŸ“Š {key} æ··åˆè®¿é—®æ¨¡å¼ï¼Œä¿æŒå½“å‰é…ç½®")
                
    def _emergency_cleanup(self, device: str):
        """ç´§æ€¥å†…å­˜æ¸…ç†"""
        print(f"[WARNING] ğŸ§¹ {device} å†…å­˜ä¸è¶³ï¼Œæ‰§è¡Œç´§æ€¥æ¸…ç†...")
        
        try:
            # æ¸…ç†æœªä½¿ç”¨çš„ç»Ÿä¸€å†…å­˜
            if device in self.unified_memory_pool:
                with self.unified_memory_locks[device]:
                    for key, in_use in list(self.unified_memory_usage[device].items()):
                        if not in_use:
                            del self.unified_memory_pool[device][key]
                            del self.unified_memory_usage[device][key]
                            
            # å¼ºåˆ¶åƒåœ¾å›æ”¶
            gc.collect()
            
            # æ¸…ç†GPUç¼“å­˜
            if 'cuda' in device:
                torch.cuda.empty_cache()
                torch.cuda.synchronize()
                
            print(f"[INFO] âœ… {device} ç´§æ€¥æ¸…ç†å®Œæˆ")
            
        except Exception as e:
            print(f"[ERROR] ç´§æ€¥æ¸…ç†å¤±è´¥: {e}")
            
    def get_unified_memory_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿä¸€å†…å­˜ç»Ÿè®¡ä¿¡æ¯"""
        total_allocations = self.stats['unified_allocations'] + self.stats['fallback_allocations']
        unified_ratio = self.stats['unified_allocations'] / max(total_allocations, 1)
        
        migration_avg_time = (self.migration_stats['migration_time_total'] / 
                            max(self.migration_stats['manual_migrations'], 1))
        
        prefetch_hit_rate = (self.stats['prefetch_hits'] / 
                           max(self.stats['prefetch_hits'] + self.stats['prefetch_misses'], 1))
        
        return {
            'unified_memory_supported': self.unified_memory_supported,
            'unified_allocation_ratio': unified_ratio,
            'total_migrations': (self.migration_stats['cpu_to_gpu_migrations'] + 
                               self.migration_stats['gpu_to_cpu_migrations']),
            'average_migration_time_ms': migration_avg_time * 1000,
            'prefetch_hit_rate': prefetch_hit_rate,
            'memory_saved_mb': self.stats['memory_saved_bytes'] / (1024**2),
            'access_violations': self.stats['access_violations']
        }
        
    def get_memory_usage(self) -> Dict[str, Dict]:
        """è·å–å†…å­˜ä½¿ç”¨æƒ…å†µ"""
        usage_info = {}
        
        for device in self.devices:
            if device == 'cpu':
                # CPUå†…å­˜ä½¿ç”¨
                memory = psutil.virtual_memory()
                usage_info['cpu'] = {
                    'total_gb': memory.total / (1024**3),
                    'used_gb': memory.used / (1024**3),
                    'percent': memory.percent,
                    'available_gb': memory.available / (1024**3)
                }
            else:
                # GPUå†…å­˜ä½¿ç”¨
                device_id = int(device.split(':')[1])
                if torch.cuda.is_available():
                    allocated = torch.cuda.memory_allocated(device_id) / (1024**3)
                    reserved = torch.cuda.memory_reserved(device_id) / (1024**3)
                    total = torch.cuda.get_device_properties(device_id).total_memory / (1024**3)
                    
                    usage_info[device] = {
                        'total_gb': total,
                        'allocated_gb': allocated,
                        'reserved_gb': reserved,
                        'percent': (allocated / total) * 100,
                        'unified_pool_count': len(self.unified_memory_pool.get(device, {}))
                    }
                    
        return usage_info
        
    def cleanup(self):
        """æ¸…ç†æ‰€æœ‰å†…å­˜èµ„æº"""
        print("[INFO] ğŸ§¹ å¼€å§‹æ¸…ç†ç»Ÿä¸€å†…å­˜ç®¡ç†å™¨...")
        
        try:
            # æ¸…ç†ç»Ÿä¸€å†…å­˜æ± 
            for device in self.devices:
                if device in self.unified_memory_pool:
                    with self.unified_memory_locks[device]:
                        self.unified_memory_pool[device].clear()
                        self.unified_memory_usage[device].clear()
                        
                if device in self.fallback_memory_pool:
                    self.fallback_memory_pool[device].clear()
                    self.fallback_usage[device].clear()
                    
            # æ¸…ç†è®¿é—®æ¨¡å¼è®°å½•
            self.access_patterns.clear()
            
            # å¼ºåˆ¶åƒåœ¾å›æ”¶
            gc.collect()
            
            # æ¸…ç†GPUç¼“å­˜
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                torch.cuda.synchronize()
                
            print("[INFO] âœ… ç»Ÿä¸€å†…å­˜ç®¡ç†å™¨æ¸…ç†å®Œæˆ")
            
        except Exception as e:
            print(f"[ERROR] æ¸…ç†ç»Ÿä¸€å†…å­˜ç®¡ç†å™¨æ—¶å‡ºé”™: {e}")

# å…¨å±€ç»Ÿä¸€å†…å­˜ç®¡ç†å™¨å®ä¾‹
_unified_memory_manager = None

def get_unified_memory_manager(device_ids: List[int] = [0], 
                             unified_pool_size_gb: float = 2.0) -> CUDAUnifiedMemoryManager:
    """è·å–å…¨å±€ç»Ÿä¸€å†…å­˜ç®¡ç†å™¨å®ä¾‹"""
    global _unified_memory_manager
    if _unified_memory_manager is None:
        _unified_memory_manager = CUDAUnifiedMemoryManager(device_ids, unified_pool_size_gb)
    return _unified_memory_manager

def cleanup_unified_memory_manager():
    """æ¸…ç†å…¨å±€ç»Ÿä¸€å†…å­˜ç®¡ç†å™¨"""
    global _unified_memory_manager
    if _unified_memory_manager is not None:
        _unified_memory_manager.cleanup()
        _unified_memory_manager = None

if __name__ == "__main__":
    # æµ‹è¯•ç»Ÿä¸€å†…å­˜ç®¡ç†å™¨
    print("[INFO] ğŸ§ª å¼€å§‹CUDAç»Ÿä¸€å†…å­˜ç®¡ç†å™¨æµ‹è¯•...")
    
    manager = CUDAUnifiedMemoryManager([0], unified_pool_size_gb=1.0)
    
    # æµ‹è¯•ç»Ÿä¸€å†…å­˜åˆ†é…
    print("\n[TEST] æµ‹è¯•ç»Ÿä¸€å†…å­˜åˆ†é…...")
    tensor1 = manager.allocate_unified_memory((1, 3, 320, 320), access_pattern='gpu_heavy')
    tensor2 = manager.allocate_unified_memory((1, 3, 320, 320), access_pattern='cpu_heavy')
    
    print(f"GPUé‡åº¦è®¿é—®å¼ é‡è®¾å¤‡: {tensor1.device}")
    print(f"CPUé‡åº¦è®¿é—®å¼ é‡è®¾å¤‡: {tensor2.device}")
    
    # æµ‹è¯•å†…å­˜è¿ç§»
    print("\n[TEST] æµ‹è¯•å†…å­˜è¿ç§»...")
    if torch.cuda.is_available():
        migrated_tensor = manager.migrate_to_device(tensor1, 'cpu')
        print(f"è¿ç§»åå¼ é‡è®¾å¤‡: {migrated_tensor.device}")
    
    # æµ‹è¯•è®¿é—®æ¨¡å¼ä¼˜åŒ–
    print("\n[TEST] æµ‹è¯•è®¿é—®æ¨¡å¼ä¼˜åŒ–...")
    manager.optimize_access_patterns()
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    print("\n[INFO] ğŸ“Š ç»Ÿä¸€å†…å­˜ç»Ÿè®¡:")
    stats = manager.get_unified_memory_stats()
    for key, value in stats.items():
        if isinstance(value, float):
            print(f"  {key}: {value:.3f}")
        else:
            print(f"  {key}: {value}")
    
    print("\n[INFO] ğŸ“ˆ å†…å­˜ä½¿ç”¨æƒ…å†µ:")
    usage = manager.get_memory_usage()
    for device, info in usage.items():
        print(f"  {device}: {info}")
    
    # æ¸…ç†
    manager.cleanup()
    print("\n[INFO] âœ… æµ‹è¯•å®Œæˆ")