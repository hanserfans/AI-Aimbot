#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GPUé‡åº¦æ¨¡å¼å¢å¼ºå™¨
é’ˆå¯¹GPUä½¿ç”¨ç‡21%çš„é—®é¢˜ï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–GPUé‡åº¦è®¿é—®æ¨¡å¼é…ç½®
"""

import json
import os
import torch
import psutil
import GPUtil
from typing import Dict, Any

class GPUHeavyModeEnhancer:
    """GPUé‡åº¦æ¨¡å¼å¢å¼ºå™¨"""
    
    def __init__(self):
        self.config_file = "gui_config.json"
        self.current_config = self.load_current_config()
        
    def load_current_config(self) -> Dict[str, Any]:
        """åŠ è½½å½“å‰é…ç½®"""
        try:
            if os.path.exists(self.config_file):
                with open(self.config_file, "r", encoding="utf-8") as f:
                    return json.load(f)
            return {}
        except Exception as e:
            print(f"[ERROR] é…ç½®åŠ è½½å¤±è´¥: {e}")
            return {}
    
    def analyze_current_gpu_usage(self) -> Dict[str, Any]:
        """åˆ†æå½“å‰GPUä½¿ç”¨æƒ…å†µ"""
        analysis = {
            'gpu_available': torch.cuda.is_available(),
            'gpu_count': 0,
            'gpu_info': [],
            'system_memory': {},
            'bottlenecks': []
        }
        
        # GPUä¿¡æ¯
        if torch.cuda.is_available():
            analysis['gpu_count'] = torch.cuda.device_count()
            
            try:
                gpus = GPUtil.getGPUs()
                for i, gpu in enumerate(gpus):
                    gpu_info = {
                        'id': i,
                        'name': gpu.name,
                        'utilization': gpu.load * 100,
                        'memory_used': gpu.memoryUsed,
                        'memory_total': gpu.memoryTotal,
                        'memory_util': gpu.memoryUtil * 100,
                        'temperature': gpu.temperature
                    }
                    analysis['gpu_info'].append(gpu_info)
                    
                    # è¯†åˆ«ç“¶é¢ˆ
                    if gpu.load < 0.5:  # GPUä½¿ç”¨ç‡ä½äº50%
                        analysis['bottlenecks'].append(f"GPU {i} ä½¿ç”¨ç‡è¿‡ä½: {gpu.load*100:.1f}%")
                    
                    if gpu.memoryUtil < 0.3:  # æ˜¾å­˜ä½¿ç”¨ç‡ä½äº30%
                        analysis['bottlenecks'].append(f"GPU {i} æ˜¾å­˜åˆ©ç”¨ç‡ä½: {gpu.memoryUtil*100:.1f}%")
                        
            except Exception as e:
                print(f"[WARNING] GPUä¿¡æ¯è·å–å¤±è´¥: {e}")
        
        # ç³»ç»Ÿå†…å­˜ä¿¡æ¯
        memory = psutil.virtual_memory()
        analysis['system_memory'] = {
            'total_gb': memory.total / 1024**3,
            'available_gb': memory.available / 1024**3,
            'used_percent': memory.percent
        }
        
        # å†…å­˜ç“¶é¢ˆæ£€æµ‹
        if memory.percent > 85:
            analysis['bottlenecks'].append(f"ç³»ç»Ÿå†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {memory.percent:.1f}%")
        
        return analysis
    
    def calculate_enhanced_config(self, analysis: Dict[str, Any]) -> Dict[str, Any]:
        """è®¡ç®—å¢å¼ºçš„GPUé‡åº¦æ¨¡å¼é…ç½®"""
        enhanced_config = {
            "use_unified_memory": True,
            "unified_memory_access_pattern": "gpu_heavy",
            "enable_auto_migration": True,
            "fallback_to_traditional_gpu": True,
            "performance_monitoring": True,
            "memory_pool_preallocation": True,
            "zero_copy_optimization": True,
            "debug_unified_memory": False
        }
        
        # æ ¹æ®åˆ†æç»“æœè°ƒæ•´é…ç½®
        if analysis['gpu_available'] and analysis['gpu_info']:
            gpu = analysis['gpu_info'][0]  # ä¸»GPU
            
            # å†…å­˜æ± å¤§å°ä¼˜åŒ–
            if gpu['memory_total'] >= 8000:  # 8GB+æ˜¾å­˜
                if analysis['system_memory']['used_percent'] > 85:
                    # ç³»ç»Ÿå†…å­˜ç´§å¼ ï¼Œå¢å¤§GPUå†…å­˜æ± 
                    enhanced_config['unified_memory_size_gb'] = 2.5
                    enhanced_config['memory_optimization_level'] = "aggressive"
                else:
                    enhanced_config['unified_memory_size_gb'] = 2.0
                    enhanced_config['memory_optimization_level'] = "balanced"
            else:
                # æ˜¾å­˜è¾ƒå°‘ï¼Œä¿å®ˆé…ç½®
                enhanced_config['unified_memory_size_gb'] = 1.0
                enhanced_config['memory_optimization_level'] = "conservative"
            
            # GPUåˆ©ç”¨ç‡ä¼˜åŒ–
            if gpu['utilization'] < 30:  # å½“å‰ä½¿ç”¨ç‡ä½
                enhanced_config.update({
                    "gpu_pipeline_optimization": True,
                    "async_gpu_processing": True,
                    "gpu_memory_pool_size_mb": 512,
                    "enable_gpu_preprocessing": True,
                    "enable_gpu_postprocessing": True,
                    "gpu_batch_processing": True,
                    "gpu_stream_processing": True
                })
            
            # æ˜¾å­˜åˆ©ç”¨ç‡ä¼˜åŒ–
            if gpu['memory_util'] < 50:  # æ˜¾å­˜ä½¿ç”¨ç‡ä½
                enhanced_config.update({
                    "increase_batch_size": True,
                    "enable_memory_prefetch": True,
                    "gpu_cache_optimization": True
                })
        
        # ç³»ç»Ÿå†…å­˜ä¼˜åŒ–
        if analysis['system_memory']['used_percent'] > 85:
            enhanced_config.update({
                "offload_to_gpu": True,
                "reduce_cpu_memory_usage": True,
                "enable_gpu_image_processing": True,
                "gpu_screen_capture": True
            })
        
        return enhanced_config
    
    def update_config_file(self, enhanced_config: Dict[str, Any]) -> bool:
        """æ›´æ–°é…ç½®æ–‡ä»¶"""
        try:
            # åˆå¹¶ç°æœ‰é…ç½®
            if "unified_memory" in self.current_config:
                self.current_config["unified_memory"].update(enhanced_config)
            else:
                self.current_config["unified_memory"] = enhanced_config
            
            # ä¿å­˜é…ç½®
            with open(self.config_file, "w", encoding="utf-8") as f:
                json.dump(self.current_config, f, indent=2, ensure_ascii=False)
            
            print(f"[SUCCESS] âœ… é…ç½®å·²æ›´æ–°åˆ° {self.config_file}")
            return True
            
        except Exception as e:
            print(f"[ERROR] âŒ é…ç½®æ›´æ–°å¤±è´¥: {e}")
            return False
    
    def print_enhancement_report(self, analysis: Dict[str, Any], enhanced_config: Dict[str, Any]):
        """æ‰“å°å¢å¼ºæŠ¥å‘Š"""
        print("\n" + "="*60)
        print("ğŸš€ GPUé‡åº¦æ¨¡å¼å¢å¼ºæŠ¥å‘Š")
        print("="*60)
        
        # å½“å‰çŠ¶æ€
        print("\nğŸ“Š å½“å‰ç³»ç»ŸçŠ¶æ€:")
        if analysis['gpu_info']:
            gpu = analysis['gpu_info'][0]
            print(f"  â€¢ GPU: {gpu['name']}")
            print(f"  â€¢ GPUä½¿ç”¨ç‡: {gpu['utilization']:.1f}% âš ï¸ {'è¿‡ä½' if gpu['utilization'] < 30 else 'æ­£å¸¸'}")
            print(f"  â€¢ æ˜¾å­˜ä½¿ç”¨: {gpu['memory_used']}MB / {gpu['memory_total']}MB ({gpu['memory_util']:.1f}%)")
            print(f"  â€¢ GPUæ¸©åº¦: {gpu['temperature']}Â°C")
        
        memory = analysis['system_memory']
        print(f"  â€¢ ç³»ç»Ÿå†…å­˜: {memory['used_percent']:.1f}% âš ï¸ {'è¿‡é«˜' if memory['used_percent'] > 85 else 'æ­£å¸¸'}")
        print(f"  â€¢ å¯ç”¨å†…å­˜: {memory['available_gb']:.1f}GB")
        
        # è¯†åˆ«çš„ç“¶é¢ˆ
        if analysis['bottlenecks']:
            print(f"\nâš ï¸ è¯†åˆ«çš„ç“¶é¢ˆ:")
            for bottleneck in analysis['bottlenecks']:
                print(f"  â€¢ {bottleneck}")
        
        # å¢å¼ºé…ç½®
        print(f"\nâš™ï¸ å¢å¼ºé…ç½®:")
        print(f"  â€¢ ç»Ÿä¸€å†…å­˜å¤§å°: {enhanced_config.get('unified_memory_size_gb', 'N/A')}GB")
        print(f"  â€¢ ä¼˜åŒ–çº§åˆ«: {enhanced_config.get('memory_optimization_level', 'N/A')}")
        print(f"  â€¢ GPUç®¡é“ä¼˜åŒ–: {'âœ…' if enhanced_config.get('gpu_pipeline_optimization') else 'âŒ'}")
        print(f"  â€¢ å¼‚æ­¥GPUå¤„ç†: {'âœ…' if enhanced_config.get('async_gpu_processing') else 'âŒ'}")
        print(f"  â€¢ GPUé¢„å¤„ç†: {'âœ…' if enhanced_config.get('enable_gpu_preprocessing') else 'âŒ'}")
        print(f"  â€¢ GPUåå¤„ç†: {'âœ…' if enhanced_config.get('enable_gpu_postprocessing') else 'âŒ'}")
        print(f"  â€¢ æ‰¹å¤„ç†ä¼˜åŒ–: {'âœ…' if enhanced_config.get('gpu_batch_processing') else 'âŒ'}")
        
        # é¢„æœŸæ•ˆæœ
        print(f"\nğŸ¯ é¢„æœŸä¼˜åŒ–æ•ˆæœ:")
        if analysis['gpu_info'] and analysis['gpu_info'][0]['utilization'] < 30:
            print(f"  â€¢ GPUä½¿ç”¨ç‡: {analysis['gpu_info'][0]['utilization']:.1f}% â†’ é¢„æœŸ 60-80%")
        
        if memory['used_percent'] > 85:
            print(f"  â€¢ ç³»ç»Ÿå†…å­˜: {memory['used_percent']:.1f}% â†’ é¢„æœŸ 70-80%")
        
        print(f"  â€¢ å¤„ç†å»¶è¿Ÿ: é¢„æœŸé™ä½ 30-50%")
        print(f"  â€¢ å¸§ç‡: é¢„æœŸæå‡ 40-60%")
        print(f"  â€¢ ç³»ç»Ÿç¨³å®šæ€§: æ˜¾è‘—æå‡")
        
        print("\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
        print("  1. é‡å¯AIç„å‡†ç¨‹åºä»¥åº”ç”¨æ–°é…ç½®")
        print("  2. ç›‘æ§GPUä½¿ç”¨ç‡å˜åŒ–")
        print("  3. å¦‚æœç³»ç»Ÿå†…å­˜ä»ç„¶ç´§å¼ ï¼Œè€ƒè™‘å…³é—­å…¶ä»–ç¨‹åº")
        print("  4. å®šæœŸæ£€æŸ¥GPUæ¸©åº¦ï¼Œç¡®ä¿æ•£çƒ­è‰¯å¥½")
        
        print("="*60)
    
    def enhance_gpu_heavy_mode(self) -> bool:
        """æ‰§è¡ŒGPUé‡åº¦æ¨¡å¼å¢å¼º"""
        print("ğŸ¯ GPUé‡åº¦æ¨¡å¼å¢å¼ºå™¨å¯åŠ¨")
        print("="*50)
        
        # åˆ†æå½“å‰çŠ¶æ€
        print("\n[STEP 1] ğŸ” åˆ†æå½“å‰GPUä½¿ç”¨æƒ…å†µ...")
        analysis = self.analyze_current_gpu_usage()
        
        if not analysis['gpu_available']:
            print("[ERROR] âŒ æœªæ£€æµ‹åˆ°å¯ç”¨çš„CUDA GPU")
            return False
        
        # è®¡ç®—å¢å¼ºé…ç½®
        print("\n[STEP 2] âš™ï¸ è®¡ç®—å¢å¼ºé…ç½®...")
        enhanced_config = self.calculate_enhanced_config(analysis)
        
        # æ›´æ–°é…ç½®æ–‡ä»¶
        print("\n[STEP 3] ğŸ’¾ æ›´æ–°é…ç½®æ–‡ä»¶...")
        success = self.update_config_file(enhanced_config)
        
        if success:
            # æ‰“å°æŠ¥å‘Š
            self.print_enhancement_report(analysis, enhanced_config)
            print("\nğŸ‰ GPUé‡åº¦æ¨¡å¼å¢å¼ºå®Œæˆï¼")
            return True
        else:
            print("\nâŒ å¢å¼ºå¤±è´¥")
            return False

def main():
    """ä¸»å‡½æ•°"""
    enhancer = GPUHeavyModeEnhancer()
    
    try:
        success = enhancer.enhance_gpu_heavy_mode()
        if success:
            print("\nğŸ’¡ æç¤º: é‡å¯AIç„å‡†ç¨‹åºä»¥åº”ç”¨å¢å¼ºé…ç½®")
        return success
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        return False
    except Exception as e:
        print(f"\nâŒ ç¨‹åºå¼‚å¸¸: {e}")
        return False

if __name__ == "__main__":
    main()