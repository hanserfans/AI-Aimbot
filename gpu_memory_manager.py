#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GPUå†…å­˜ç®¡ç†å™¨
å®ç°å…±äº«GPUå†…å­˜ã€å†…å­˜æ± ã€é›¶æ‹·è´æŠ€æœ¯
è§£å†³å†…å­˜ä¸è¶³é—®é¢˜ï¼Œæé«˜GPUåˆ©ç”¨ç‡
"""

import torch
import numpy as np
import time
import gc
from typing import Dict, List, Tuple, Optional, Any
from collections import defaultdict
import threading
import psutil

class GPUMemoryManager:
    """GPUå†…å­˜ç®¡ç†å™¨ - å®ç°å…±äº«GPUå†…å­˜å’Œå†…å­˜æ± """
    
    def __init__(self, device_ids: List[int] = [0], pool_size_gb: float = 4.0):
        """
        åˆå§‹åŒ–GPUå†…å­˜ç®¡ç†å™¨
        
        Args:
            device_ids: GPUè®¾å¤‡IDåˆ—è¡¨
            pool_size_gb: å†…å­˜æ± å¤§å°(GB)
        """
        self.device_ids = device_ids
        self.pool_size_bytes = int(pool_size_gb * 1024**3)
        self.devices = [f'cuda:{i}' for i in device_ids if torch.cuda.is_available()]
        
        if not self.devices:
            self.devices = ['cpu']
            print("[WARNING] æ— å¯ç”¨GPUï¼Œä½¿ç”¨CPUæ¨¡å¼")
        
        # å†…å­˜æ±  - æ¯ä¸ªè®¾å¤‡ä¸€ä¸ªæ± 
        self.memory_pools = {}
        self.pool_usage = {}
        self.pool_locks = {}
        
        # å…±äº«å†…å­˜åŒºåŸŸ
        self.shared_memory = {}
        self.shared_locks = {}
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'allocations': 0,
            'deallocations': 0,
            'cache_hits': 0,
            'cache_misses': 0,
            'memory_saved_bytes': 0,
            'peak_memory_usage': 0
        }
        
        # åˆå§‹åŒ–å†…å­˜æ± 
        self._initialize_memory_pools()
        
        print(f"[INFO] ğŸŠ GPUå†…å­˜ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"[INFO] è®¾å¤‡: {self.devices}")
        print(f"[INFO] å†…å­˜æ± å¤§å°: {pool_size_gb:.1f}GB")
        
    def _initialize_memory_pools(self):
        """åˆå§‹åŒ–å†…å­˜æ± """
        for device in self.devices:
            if device == 'cpu':
                continue
                
            try:
                self.memory_pools[device] = {}
                self.pool_usage[device] = {}
                self.pool_locks[device] = threading.Lock()
                self.shared_memory[device] = {}
                self.shared_locks[device] = threading.Lock()
                
                # é¢„åˆ†é…å¸¸ç”¨å°ºå¯¸çš„å†…å­˜å—
                common_sizes = [
                    (1, 3, 320, 320),    # æ ‡å‡†æ£€æµ‹å›¾åƒ
                    (1, 3, 640, 640),    # é«˜åˆ†è¾¨ç‡æ£€æµ‹
                    (1920, 1080, 3),     # å…¨å±æˆªå›¾
                    (320, 320, 3),       # å¤„ç†åå›¾åƒ
                    (100, 6),            # æ£€æµ‹ç»“æœ
                ]
                
                for size in common_sizes:
                    self._preallocate_buffer(device, size)
                    
                print(f"[INFO] ğŸ“¦ {device} å†…å­˜æ± åˆå§‹åŒ–å®Œæˆï¼Œé¢„åˆ†é…{len(common_sizes)}ä¸ªç¼“å†²åŒº")
                
            except Exception as e:
                print(f"[WARNING] {device} å†…å­˜æ± åˆå§‹åŒ–å¤±è´¥: {e}")
                
    def _preallocate_buffer(self, device: str, size: Tuple, dtype=torch.float16):
        """é¢„åˆ†é…å†…å­˜ç¼“å†²åŒº"""
        try:
            key = f"{size}_{dtype}"
            buffer = torch.empty(size, dtype=dtype, device=device)
            
            with self.pool_locks[device]:
                self.memory_pools[device][key] = buffer
                self.pool_usage[device][key] = False
                
        except Exception as e:
            print(f"[WARNING] é¢„åˆ†é…ç¼“å†²åŒºå¤±è´¥ {device} {size}: {e}")
            
    def allocate_tensor(self, size: Tuple, dtype=torch.float16, device: str = None) -> torch.Tensor:
        """
        åˆ†é…GPUå¼ é‡ï¼ˆæ”¯æŒå†…å­˜æ± å¤ç”¨ï¼‰
        
        Args:
            size: å¼ é‡å°ºå¯¸
            dtype: æ•°æ®ç±»å‹
            device: ç›®æ ‡è®¾å¤‡
            
        Returns:
            GPUå¼ é‡
        """
        if device is None:
            device = self.devices[0]
            
        key = f"{size}_{dtype}"
        
        # å°è¯•ä»å†…å­˜æ± è·å–
        if device in self.memory_pools:
            with self.pool_locks[device]:
                if key in self.memory_pools[device] and not self.pool_usage[device].get(key, True):
                    self.pool_usage[device][key] = True
                    self.stats['cache_hits'] += 1
                    self.stats['memory_saved_bytes'] += torch.tensor(size).prod().item() * dtype.itemsize if hasattr(dtype, 'itemsize') else 4
                    return self.memory_pools[device][key]
        
        # åˆ›å»ºæ–°å¼ é‡
        try:
            tensor = torch.empty(size, dtype=dtype, device=device)
            self.stats['allocations'] += 1
            self.stats['cache_misses'] += 1
            return tensor
        except torch.cuda.OutOfMemoryError:
            # å†…å­˜ä¸è¶³æ—¶æ¸…ç†å¹¶é‡è¯•
            self._emergency_cleanup(device)
            return torch.empty(size, dtype=dtype, device=device)
            
    def deallocate_tensor(self, tensor: torch.Tensor):
        """é‡Šæ”¾å¼ é‡ï¼ˆè¿”å›å†…å­˜æ± ï¼‰"""
        if not tensor.is_cuda:
            return
            
        device = str(tensor.device)
        size = tuple(tensor.shape)
        dtype = tensor.dtype
        key = f"{size}_{dtype}"
        
        # è¿”å›å†…å­˜æ± 
        if device in self.pool_usage and key in self.pool_usage[device]:
            with self.pool_locks[device]:
                self.pool_usage[device][key] = False
                self.stats['deallocations'] += 1
                
    def create_shared_memory(self, name: str, size: Tuple, dtype=torch.float16, device: str = None) -> torch.Tensor:
        """
        åˆ›å»ºå…±äº«GPUå†…å­˜åŒºåŸŸ
        
        Args:
            name: å…±äº«å†…å­˜åç§°
            size: å†…å­˜å¤§å°
            dtype: æ•°æ®ç±»å‹
            device: ç›®æ ‡è®¾å¤‡
            
        Returns:
            å…±äº«å†…å­˜å¼ é‡
        """
        if device is None:
            device = self.devices[0]
            
        if device not in self.shared_memory:
            return self.allocate_tensor(size, dtype, device)
            
        with self.shared_locks[device]:
            if name not in self.shared_memory[device]:
                self.shared_memory[device][name] = torch.empty(size, dtype=dtype, device=device)
                print(f"[INFO] ğŸ”— åˆ›å»ºå…±äº«å†…å­˜åŒºåŸŸ: {name} on {device}")
                
            return self.shared_memory[device][name]
            
    def get_shared_memory(self, name: str, device: str = None) -> Optional[torch.Tensor]:
        """è·å–å…±äº«å†…å­˜åŒºåŸŸ"""
        if device is None:
            device = self.devices[0]
            
        if device in self.shared_memory:
            with self.shared_locks[device]:
                return self.shared_memory[device].get(name)
        return None
        
    def zero_copy_transfer(self, data: np.ndarray, target_device: str = None) -> torch.Tensor:
        """
        é›¶æ‹·è´æ•°æ®ä¼ è¾“ï¼ˆå°½å¯èƒ½é¿å…å†…å­˜æ‹·è´ï¼‰
        
        Args:
            data: æºæ•°æ®
            target_device: ç›®æ ‡è®¾å¤‡
            
        Returns:
            GPUå¼ é‡
        """
        if target_device is None:
            target_device = self.devices[0]
            
        try:
            # ä½¿ç”¨pin_memoryåŠ é€ŸCPUåˆ°GPUä¼ è¾“
            if isinstance(data, np.ndarray):
                # åˆ›å»ºpinned memory
                tensor_cpu = torch.from_numpy(data).pin_memory()
                # å¼‚æ­¥ä¼ è¾“åˆ°GPU
                tensor_gpu = tensor_cpu.to(target_device, non_blocking=True)
                return tensor_gpu
            else:
                return torch.as_tensor(data, device=target_device)
                
        except Exception as e:
            print(f"[WARNING] é›¶æ‹·è´ä¼ è¾“å¤±è´¥: {e}")
            return torch.tensor(data, device=target_device)
            
    def batch_allocate(self, sizes: List[Tuple], dtype=torch.float16, device: str = None) -> List[torch.Tensor]:
        """æ‰¹é‡åˆ†é…å¼ é‡ï¼ˆæé«˜æ•ˆç‡ï¼‰"""
        if device is None:
            device = self.devices[0]
            
        tensors = []
        for size in sizes:
            tensor = self.allocate_tensor(size, dtype, device)
            tensors.append(tensor)
            
        return tensors
        
    def _emergency_cleanup(self, device: str):
        """ç´§æ€¥å†…å­˜æ¸…ç†"""
        print(f"[WARNING] {device} å†…å­˜ä¸è¶³ï¼Œæ‰§è¡Œç´§æ€¥æ¸…ç†...")
        
        try:
            # æ¸…ç†æœªä½¿ç”¨çš„å†…å­˜æ± 
            if device in self.memory_pools:
                with self.pool_locks[device]:
                    unused_keys = [k for k, used in self.pool_usage[device].items() if not used]
                    for key in unused_keys:
                        if key in self.memory_pools[device]:
                            del self.memory_pools[device][key]
                            del self.pool_usage[device][key]
                            
            # å¼ºåˆ¶GPUåƒåœ¾å›æ”¶
            if device != 'cpu':
                torch.cuda.empty_cache()
                
            # ç³»ç»Ÿåƒåœ¾å›æ”¶
            gc.collect()
            
            print(f"[INFO] {device} ç´§æ€¥æ¸…ç†å®Œæˆ")
            
        except Exception as e:
            print(f"[ERROR] ç´§æ€¥æ¸…ç†å¤±è´¥: {e}")
            
    def get_memory_usage(self) -> Dict[str, Dict]:
        """è·å–å†…å­˜ä½¿ç”¨æƒ…å†µ"""
        usage = {}
        
        for device in self.devices:
            if device == 'cpu':
                # CPUå†…å­˜ä½¿ç”¨
                memory = psutil.virtual_memory()
                usage[device] = {
                    'used_gb': (memory.total - memory.available) / 1024**3,
                    'total_gb': memory.total / 1024**3,
                    'percent': memory.percent
                }
            else:
                # GPUå†…å­˜ä½¿ç”¨
                try:
                    device_id = int(device.split(':')[1])
                    allocated = torch.cuda.memory_allocated(device_id) / 1024**3
                    reserved = torch.cuda.memory_reserved(device_id) / 1024**3
                    total = torch.cuda.get_device_properties(device_id).total_memory / 1024**3
                    
                    usage[device] = {
                        'allocated_gb': allocated,
                        'reserved_gb': reserved,
                        'total_gb': total,
                        'percent': (allocated / total) * 100
                    }
                except:
                    usage[device] = {'error': 'Unable to get GPU memory info'}
                    
        return usage
        
    def get_pool_statistics(self) -> Dict:
        """è·å–å†…å­˜æ± ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.stats.copy()
        
        # è®¡ç®—å†…å­˜æ± ä½¿ç”¨ç‡
        total_buffers = 0
        used_buffers = 0
        
        for device in self.memory_pools:
            device_total = len(self.memory_pools[device])
            device_used = sum(1 for used in self.pool_usage[device].values() if used)
            
            total_buffers += device_total
            used_buffers += device_used
            
        if total_buffers > 0:
            stats['pool_usage_percent'] = (used_buffers / total_buffers) * 100
        else:
            stats['pool_usage_percent'] = 0
            
        # ç¼“å­˜å‘½ä¸­ç‡
        total_requests = stats['cache_hits'] + stats['cache_misses']
        if total_requests > 0:
            stats['cache_hit_rate'] = (stats['cache_hits'] / total_requests) * 100
        else:
            stats['cache_hit_rate'] = 0
            
        # å†…å­˜èŠ‚çœ
        stats['memory_saved_mb'] = stats['memory_saved_bytes'] / 1024**2
        
        return stats
        
    def optimize_memory_layout(self):
        """ä¼˜åŒ–å†…å­˜å¸ƒå±€"""
        print("[INFO] ğŸ”§ å¼€å§‹å†…å­˜å¸ƒå±€ä¼˜åŒ–...")
        
        for device in self.devices:
            if device == 'cpu':
                continue
                
            try:
                # æ¸…ç†ç¢ç‰‡åŒ–å†…å­˜
                if device.startswith('cuda'):
                    torch.cuda.empty_cache()
                    
                # é‡æ–°æ•´ç†å†…å­˜æ± 
                self._reorganize_memory_pool(device)
                
            except Exception as e:
                print(f"[WARNING] {device} å†…å­˜ä¼˜åŒ–å¤±è´¥: {e}")
                
        print("[INFO] âœ… å†…å­˜å¸ƒå±€ä¼˜åŒ–å®Œæˆ")
        
    def _reorganize_memory_pool(self, device: str):
        """é‡æ–°æ•´ç†å†…å­˜æ± """
        if device not in self.memory_pools:
            return
            
        with self.pool_locks[device]:
            # é‡Šæ”¾æœªä½¿ç”¨çš„ç¼“å†²åŒº
            unused_keys = [k for k, used in self.pool_usage[device].items() if not used]
            for key in unused_keys[:len(unused_keys)//2]:  # åªé‡Šæ”¾ä¸€åŠï¼Œä¿ç•™ä¸€äº›ç¼“å­˜
                if key in self.memory_pools[device]:
                    del self.memory_pools[device][key]
                    del self.pool_usage[device][key]
                    
    def cleanup(self):
        """æ¸…ç†æ‰€æœ‰GPUèµ„æº"""
        print("[INFO] ğŸ§¹ å¼€å§‹GPUå†…å­˜ç®¡ç†å™¨æ¸…ç†...")
        
        try:
            # æ¸…ç†å†…å­˜æ± 
            for device in self.memory_pools:
                with self.pool_locks[device]:
                    self.memory_pools[device].clear()
                    self.pool_usage[device].clear()
                    
            # æ¸…ç†å…±äº«å†…å­˜
            for device in self.shared_memory:
                with self.shared_locks[device]:
                    self.shared_memory[device].clear()
                    
            # æ¸…ç†GPUç¼“å­˜
            for device in self.devices:
                if device.startswith('cuda'):
                    torch.cuda.empty_cache()
                    
            # é‡ç½®ç»Ÿè®¡
            for key in self.stats:
                self.stats[key] = 0
                
            print("[INFO] âœ… GPUå†…å­˜ç®¡ç†å™¨æ¸…ç†å®Œæˆ")
            
        except Exception as e:
            print(f"[WARNING] GPUå†…å­˜ç®¡ç†å™¨æ¸…ç†å¤±è´¥: {e}")

# å…¨å±€å†…å­˜ç®¡ç†å™¨å®ä¾‹
_memory_manager = None

def get_gpu_memory_manager(device_ids: List[int] = [0], pool_size_gb: float = 4.0) -> GPUMemoryManager:
    """è·å–GPUå†…å­˜ç®¡ç†å™¨å•ä¾‹"""
    global _memory_manager
    if _memory_manager is None:
        _memory_manager = GPUMemoryManager(device_ids, pool_size_gb)
    return _memory_manager

def cleanup_gpu_memory_manager():
    """æ¸…ç†GPUå†…å­˜ç®¡ç†å™¨"""
    global _memory_manager
    if _memory_manager is not None:
        _memory_manager.cleanup()
        _memory_manager = None

if __name__ == "__main__":
    # æµ‹è¯•GPUå†…å­˜ç®¡ç†å™¨
    print("[INFO] ğŸ§ª å¼€å§‹GPUå†…å­˜ç®¡ç†å™¨æµ‹è¯•...")
    
    manager = GPUMemoryManager([0], pool_size_gb=1.0)
    
    # æµ‹è¯•å†…å­˜åˆ†é…
    print("\n[TEST] æµ‹è¯•å†…å­˜åˆ†é…...")
    tensor1 = manager.allocate_tensor((1, 3, 320, 320))
    tensor2 = manager.allocate_tensor((1, 3, 320, 320))  # åº”è¯¥å¤ç”¨å†…å­˜æ± 
    
    print(f"å¼ é‡1è®¾å¤‡: {tensor1.device}")
    print(f"å¼ é‡2è®¾å¤‡: {tensor2.device}")
    
    # æµ‹è¯•å…±äº«å†…å­˜
    print("\n[TEST] æµ‹è¯•å…±äº«å†…å­˜...")
    shared_tensor = manager.create_shared_memory("test_shared", (100, 100))
    retrieved_tensor = manager.get_shared_memory("test_shared")
    print(f"å…±äº«å†…å­˜åˆ›å»ºæˆåŠŸ: {shared_tensor is not None}")
    print(f"å…±äº«å†…å­˜æ£€ç´¢æˆåŠŸ: {retrieved_tensor is not None}")
    
    # æµ‹è¯•é›¶æ‹·è´ä¼ è¾“
    print("\n[TEST] æµ‹è¯•é›¶æ‹·è´ä¼ è¾“...")
    test_data = np.random.rand(320, 320, 3).astype(np.float32)
    gpu_tensor = manager.zero_copy_transfer(test_data)
    print(f"é›¶æ‹·è´ä¼ è¾“æˆåŠŸ: {gpu_tensor.device}")
    
    # è·å–ç»Ÿè®¡ä¿¡æ¯
    print("\n[INFO] ğŸ“Š å†…å­˜ä½¿ç”¨ç»Ÿè®¡:")
    usage = manager.get_memory_usage()
    for device, info in usage.items():
        print(f"  {device}: {info}")
        
    stats = manager.get_pool_statistics()
    print(f"\n[INFO] ğŸ“ˆ å†…å­˜æ± ç»Ÿè®¡:")
    print(f"  ç¼“å­˜å‘½ä¸­ç‡: {stats['cache_hit_rate']:.1f}%")
    print(f"  å†…å­˜æ± ä½¿ç”¨ç‡: {stats['pool_usage_percent']:.1f}%")
    print(f"  èŠ‚çœå†…å­˜: {stats['memory_saved_mb']:.1f}MB")
    
    # æ¸…ç†èµ„æº
    manager.cleanup()
    print("\n[INFO] âœ… æµ‹è¯•å®Œæˆ")